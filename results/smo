=== Run information ===

Scheme:       weka.classifiers.functions.SMO -C 1.0 -L 0.001 -P 1.0E-12 -N 0 -V -1 -W 1 -K "weka.classifiers.functions.supportVector.PolyKernel -E 1.0 -C 250007" -calibrator "weka.classifiers.functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4"
Relation:     base2-weka.filters.unsupervised.attribute.Normalize-S1.0-T0.0-unset-class-temporarily
Instances:    224
Attributes:   201
              [list of attributes omitted]
Test mode:    10-fold cross-validation

=== Classifier model (full training set) ===

SMO

Kernel used:
  Linear Kernel: K(x,y) = <x,y>

Classifier for classes: não, sim

BinarySMO

Machine linear: showing attribute weights, not support vectors.

         0.0703 * (normalized) att1
 +       0.2705 * (normalized) att2
 +       0.0876 * (normalized) att4
 +       0.0499 * (normalized) att5
 +       0.1406 * (normalized) att6
 +      -0.1389 * (normalized) att7
 +       0.2406 * (normalized) att8
 +      -0.1535 * (normalized) att9
 +       0.0229 * (normalized) att10
 +       0.0876 * (normalized) att11
 +       0.0876 * (normalized) att12
 +      -0.0214 * (normalized) att13
 +      -0      * (normalized) att14
 +       0.0682 * (normalized) att15
 +      -0.0151 * (normalized) att16
 +      -0.1145 * (normalized) att17
 +      -0.3189 * (normalized) att18
 +       0.0876 * (normalized) att19
 +      -0.5    * (normalized) att20
 +       0.0774 * (normalized) att21
 +       0.1375 * (normalized) att22
 +       0.0335 * (normalized) att23
 +      -0.1765 * (normalized) att24
 +      -0.3712 * (normalized) att25
 +       0.0229 * (normalized) att26
 +       0.0962 * (normalized) att27
 +       0.0479 * (normalized) att29
 +       0.0012 * (normalized) att30
 +      -0.0862 * (normalized) att31
 +       0.1779 * (normalized) att32
 +       0.0876 * (normalized) att33
 +      -0.4084 * (normalized) att34
 +      -0.0467 * (normalized) att35
 +      -0.2019 * (normalized) att36
 +       0.0499 * (normalized) att37
 +       0.0504 * (normalized) att38
 +       0.0499 * (normalized) att39
 +      -0.2318 * (normalized) att40
 +      -0.0431 * (normalized) att41
 +      -0.0036 * (normalized) att42
 +      -0      * (normalized) att43
 +      -0.0144 * (normalized) att44
 +      -0      * (normalized) att45
 +      -0.0898 * (normalized) att46
 +       0.5327 * (normalized) att47
 +       0.0876 * (normalized) att49
 +      -0.0467 * (normalized) att50
 +      -0.0862 * (normalized) att51
 +       0.1698 * (normalized) att52
 +      -0.0066 * (normalized) att53
 +       0.8059 * (normalized) att54
 +      -1.5297 * (normalized) att55
 +      -0      * (normalized) att56
 +      -0.0862 * (normalized) att57
 +      -0.0467 * (normalized) att58
 +      -0.0037 * (normalized) att59
 +      -0      * (normalized) att60
 +       0.2203 * (normalized) att61
 +      -0.1721 * (normalized) att62
 +       0.0499 * (normalized) att63
 +       0.0703 * (normalized) att64
 +       0.0499 * (normalized) att65
 +      -0.2665 * (normalized) att66
 +      -0.1472 * (normalized) att67
 +      -0.0467 * (normalized) att68
 +       0.0006 * (normalized) att69
 +      -0      * (normalized) att70
 +      -0.0037 * (normalized) att71
 +      -0.244  * (normalized) att73
 +       0.025  * (normalized) att74
 +      -0      * (normalized) att75
 +      -0      * (normalized) att76
 +      -0.3182 * (normalized) att77
 +       0.3088 * (normalized) att78
 +      -0.0037 * (normalized) att79
 +       0.0504 * (normalized) att80
 +       0.0917 * (normalized) att81
 +       0.1406 * (normalized) att82
 +       0.1305 * (normalized) att83
 +       0.0499 * (normalized) att84
 +       0.0545 * (normalized) att85
 +       0.0499 * (normalized) att86
 +      -0      * (normalized) att87
 +       1.9826 * (normalized) att88
 +      -0.3297 * (normalized) att89
 +       0.0817 * (normalized) att90
 +      -0      * (normalized) att91
 +       0.1375 * (normalized) att93
 +       0.1406 * (normalized) att94
 +       0.0415 * (normalized) att95
 +       0.0876 * (normalized) att96
 +       0.7009 * (normalized) att97
 +      -0      * (normalized) att98
 +      -0.1197 * (normalized) att99
 +      -0      * (normalized) att100
 +       0.1406 * (normalized) att101
 +       0.0504 * (normalized) att102
 +       1.0504 * (normalized) att103
 +       0.147  * (normalized) att104
 +      -0      * (normalized) att105
 +       0.0504 * (normalized) att106
 +      -0      * (normalized) att107
 +      -0.082  * (normalized) att108
 +       0.0504 * (normalized) att109
 +      -0.0467 * (normalized) att110
 +       0.0504 * (normalized) att111
 +       0.1406 * (normalized) att112
 +      -0.0467 * (normalized) att113
 +      -0      * (normalized) att114
 +       0.0876 * (normalized) att115
 +       0.0458 * (normalized) att116
 +       0.0876 * (normalized) att117
 +       0.0504 * (normalized) att118
 +       0.0504 * (normalized) att119
 +       0.0744 * (normalized) att120
 +      -0.016  * (normalized) att121
 +       0.191  * (normalized) att122
 +      -0      * (normalized) att123
 +      -0.0467 * (normalized) att125
 +       0.8513 * (normalized) att126
 +       0.6381 * (normalized) att127
 +      -0.0467 * (normalized) att128
 +      -0      * (normalized) att129
 +      -0      * (normalized) att130
 +       0.0876 * (normalized) att131
 +      -0.3647 * (normalized) att132
 +       0.1334 * (normalized) att133
 +       0.1275 * (normalized) att134
 +       0.0876 * (normalized) att135
 +      -0.2079 * (normalized) att136
 +       0.0876 * (normalized) att137
 +      -0      * (normalized) att138
 +      -0      * (normalized) att139
 +       0.0876 * (normalized) att140
 +       0.0876 * (normalized) att141
 +       0.0876 * (normalized) att142
 +       0.0876 * (normalized) att143
 +       0.6408 * (normalized) att144
 +       0.1406 * (normalized) att145
 +       0      * (normalized) att146
 +      -0.079  * (normalized) att147
 +      -0      * (normalized) att148
 +       0.0499 * (normalized) att149
 +      -0.0431 * (normalized) att150
 +      -0.0467 * (normalized) att151
 +       0.0499 * (normalized) att152
 +      -0.0131 * (normalized) att153
 +       0.0645 * (normalized) att155
 +       0.0995 * (normalized) att156
 +      -0.1292 * (normalized) att157
 +       0.0876 * (normalized) att158
 +       0.0504 * (normalized) att159
 +      -0.0467 * (normalized) att160
 +       0.0499 * (normalized) att161
 +      -0.1329 * (normalized) att163
 +       0.0876 * (normalized) att164
 +      -0.2318 * (normalized) att165
 +       0.0876 * (normalized) att166
 +       0.0504 * (normalized) att167
 +       0.1305 * (normalized) att168
 +      -0.0467 * (normalized) att169
 +      -0.0467 * (normalized) att170
 +      -0.0467 * (normalized) att171
 +      -0.0467 * (normalized) att172
 +       0.4691 * (normalized) att173
 +       0.0504 * (normalized) att174
 +       0.0876 * (normalized) att175
 +      -0      * (normalized) att176
 +       0.0504 * (normalized) att177
 +      -0      * (normalized) att178
 +       0.2091 * (normalized) att179
 +       0.0876 * (normalized) att180
 +      -0.0467 * (normalized) att181
 +       0.0504 * (normalized) att182
 +       0.1698 * (normalized) att183
 +      -0.0467 * (normalized) att184
 +       0.0504 * (normalized) att185
 +       0.0876 * (normalized) att186
 +      -0.0467 * (normalized) att187
 +      -0.0862 * (normalized) att188
 +       0.0504 * (normalized) att189
 +      -0      * (normalized) att191
 +       0.8513 * (normalized) att192
 +      -0.0862 * (normalized) att193
 +       0.0504 * (normalized) att194
 +      -0.0467 * (normalized) att195
 +       0.0504 * (normalized) att196
 +      -0.0467 * (normalized) att197
 +      -0.1292 * (normalized) att198
 +      -0.0467 * (normalized) att199
 +      -0.4726 * (normalized) att200
 -       1.0998

Number of kernel evaluations: 14748 (90.768% cached)



Time taken to build model: 0.16 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         189               84.375  %
Incorrectly Classified Instances        35               15.625  %
Kappa statistic                          0.6861
Mean absolute error                      0.1563
Root mean squared error                  0.3953
Relative absolute error                 31.2692 %
Root relative squared error             79.0774 %
Total Number of Instances              224     

=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 0.913    0.229    0.808      0.913    0.857      0.692    0.842     0.782     não
                 0.771    0.087    0.894      0.771    0.828      0.692    0.842     0.800     sim
Weighted Avg.    0.844    0.160    0.850      0.844    0.843      0.692    0.842     0.791     

=== Confusion Matrix ===

   a   b   <-- classified as
 105  10 |   a = não
  25  84 |   b = sim

